{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Praveena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample text\n",
    "text = gutenberg.raw('austen-sense.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into lines\n",
    "lines = text.splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of Hyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches for hyphen pattern [2-5]-[b-f]: []\n"
     ]
    }
   ],
   "source": [
    "pattern_hyphen = r'\\b[2-5]-[b-f]\\b'\n",
    "matches_hyphen = re.findall(pattern_hyphen, text)\n",
    "print(\"Matches for hyphen pattern [2-5]-[b-f]:\", matches_hyphen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use of carat symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines starting with a capitalized word (caret ^):\n",
      " ['CHAPTER 1', 'The family of Dashwood had long been settled in Sussex.', 'Their estate was large, and their residence was at Norland Park,', 'The late owner of this estate was a single man, who lived', 'But her death, which happened ten years before his own,']\n"
     ]
    }
   ],
   "source": [
    "# Matches lines starting with a capitalized word (for example).\n",
    "pattern_caret = r'^[A-Z][a-z]*'\n",
    "matches_caret = [line for line in lines if re.match(pattern_caret, line)]\n",
    "print(\"Lines starting with a capitalized word (caret ^):\\n\", matches_caret[:5])  # Show first 5 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches for optional preceding words (is|was)? happy: ['was\\nhappy', 'was happy']\n"
     ]
    }
   ],
   "source": [
    "pattern_question =r'\\b(?:is|was)\\s+happy\\b'\n",
    "matches_question = re.findall(pattern_question, text)\n",
    "print(\"Matches for optional preceding words (is|was)? happy:\", matches_question[:5])  # Show first 5 matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 9) (294939484.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(\"b\" + \"a\" * total_bounda\"*flex flow.text!!\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 9)\n"
     ]
    }
   ],
   "source": [
    "# Importing Kleene star concept via iteration\n",
    "# Generate strings using Kleene *\n",
    "\n",
    "# Base string\n",
    "base = \"b\" + \"a\" * 2 + \"!\"  # Minimum \"baa!\"\n",
    "\n",
    "# Using Kleene star to generate variations\n",
    "for i in range(4):  # Kleene star ensures 0 or more 'a's added\n",
    "    print(\"b\" + \"a\" * total_bounda\"*flex flow.text!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baa!\n",
      "baaa!\n",
      "baaaa!\n",
      "baaaaa!\n"
     ]
    }
   ],
   "source": [
    "# Generate strings using the Kleene + concept (one or more repetitions)\n",
    "for i in range(2, 6):  # Start from 2 'a's to match \"baa!\" and go up to 5 'a's\n",
    "    print(\"b\" + \"a\" * i + \"!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched words: ['began', 'begin', 'begun']\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\bbeg.n\\b'\n",
    "\n",
    "# Find all matches in the text\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Print unique matches\n",
    "print(\"Matched words:\", sorted(set(matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched words: ['ing', 'tion']\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\b[a-z]*?(tion|ing)\\b'\n",
    "\n",
    "# Find all matches in the text\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Print unique matches\n",
    "print(\"Matched words:\", sorted(set(matches)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-word boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched words: ['amentation', 'ariation', 'ation', 'bjection', 'bligation', 'bservation', 'ccommodation', 'ccupation', 'ction', 'ddition', 'dition', 'dtion', 'editation', 'eflection', 'elation', 'elicitation', 'emonstration', 'eneration', 'ensation', 'ention', 'eparation', 'epresentation', 'erfection', 'ersecution', 'ffection', 'ffliction', 'irection', 'isqualification', 'ituation', 'lantation', 'lteration', 'magination', 'mperfection', 'nclination', 'nintention', 'nsinuation', 'nstruction', 'ntention', 'nticipation', 'nvitation', 'olicitation', 'ondition', 'ongratulation', 'onnection', 'onsideration', 'onstitution', 'onversation', 'otion', 'oundation', 'reparation', 'rescription', 'roportion', 'rotestation', 'rration', 'ssertion', 'tation', 'ttention', 'ttraction', 'ualification', 'uestion', 'umiliation', 'xclamation', 'xertion', 'xpectation', 'xplanation']\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\B\\w*tion\\B'\n",
    "\n",
    "\n",
    "# Find all matches in the text\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Print unique matches\n",
    "print(\"Matched words:\", sorted(set(matches)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
